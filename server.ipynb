{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASAU\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothong received from client\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-19 04:43:40         1408\n",
      "metadata.json                                  2023-01-19 04:43:40           64\n",
      "variables.h5                                   2023-01-19 04:43:40        10832\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-19 04:43:41         2468\n",
      "metadata.json                                  2023-01-19 04:43:41           64\n",
      "variables.h5                                   2023-01-19 04:43:41        53032\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-19 04:43:46         7126\n",
      "metadata.json                                  2023-01-19 04:43:46           64\n",
      "variables.h5                                   2023-01-19 04:43:46     11710216\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv2d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_5\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\dropout_3\n",
      "......vars\n",
      "...layers\\dropout_4\n",
      "......vars\n",
      "...layers\\dropout_5\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\max_pooling2d\n",
      "......vars\n",
      "...layers\\max_pooling2d_1\n",
      "......vars\n",
      "...layers\\max_pooling2d_2\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-19 04:43:48         2477\n",
      "metadata.json                                  2023-01-19 04:43:48           64\n",
      "variables.h5                                   2023-01-19 04:43:48        47856\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-19 04:43:49         2468\n",
      "metadata.json                                  2023-01-19 04:43:49           64\n",
      "variables.h5                                   2023-01-19 04:43:49        53032\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-19 04:43:49         2468\n",
      "metadata.json                                  2023-01-19 04:43:49           64\n",
      "variables.h5                                   2023-01-19 04:43:49        53032\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-19 04:43:54         7143\n",
      "metadata.json                                  2023-01-19 04:43:54           64\n",
      "variables.h5                                   2023-01-19 04:43:54     11710216\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv2d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_5\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\dropout_3\n",
      "......vars\n",
      "...layers\\dropout_4\n",
      "......vars\n",
      "...layers\\dropout_5\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\max_pooling2d\n",
      "......vars\n",
      "...layers\\max_pooling2d_1\n",
      "......vars\n",
      "...layers\\max_pooling2d_2\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-19 04:43:56         2468\n",
      "metadata.json                                  2023-01-19 04:43:56           64\n",
      "variables.h5                                   2023-01-19 04:43:56        53032\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import threading\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pygad.kerasga\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import string\n",
    "import socket\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "import os \n",
    "malicious=[]\n",
    "# Insert code at beginning of script to load score from backup\n",
    "dir_path = 'C:/Users/ASAU/OneDrive/Desktop'\n",
    "back_up = os.path.join(dir_path, 'backup.txt')\n",
    "models = os.path.join(dir_path, 'models.txt')\n",
    "#because of multiclass datasets\n",
    "from keras.utils.np_utils import to_categorical \n",
    "import random\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "assert(x_train.shape[0] == y_train.shape[0]), \"The number of images is not equal ..\"\n",
    "assert(x_test.shape[0] == y_test.shape[0]), \"The number of images is not equal ..\"\n",
    "assert(x_train.shape[1:] == (28, 28)), \"The dimension of the images are not 28x28\"\n",
    "assert(x_test.shape[1:] == (28, 28))\n",
    "num_of_samples = []\n",
    "\n",
    "cols = 5\n",
    "num_of_classes = 10\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10) \n",
    "x_train = x_train/255 \n",
    "x_test = x_test/255\n",
    "num_pixels = 784\n",
    "x_train = x_train.reshape(x_train.shape[0],\n",
    "                         num_pixels)\n",
    "x_test = x_test.reshape(x_test.shape[0],\n",
    "                         num_pixels)\n",
    "# print(x_train.shape)\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim = num_pixels,\n",
    "                    activation = 'relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "    model.compile(Adam(lr=0.01),\n",
    "                    loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model           \n",
    "     \n",
    "\n",
    "globalmodel = create_model()\n",
    "# print(model.summary())\n",
    "# history = model.fit(x_train, y_train, validation_split=0.1,\n",
    "#          epochs=10, batch_size=200, verbose=1, shuffle=1)\n",
    "\n",
    "score = globalmodel.evaluate(x_test, y_test, verbose=0)\n",
    "# print(type(score))\n",
    "# print('Test Score:', score[0])\n",
    "# print('Test Accuracy:', score[1])\n",
    "\n",
    "class SocketThread(threading.Thread):\n",
    "\n",
    "    def __init__(self, buffer_size, port,i):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.buffer_size = buffer_size\n",
    "        self.port=port\n",
    "        self.soc = socket.socket(family=socket.AF_INET, type=socket.SOCK_STREAM)\n",
    "        self.soc.bind((\"192.168.56.1\" , self.port))\n",
    "        # print(\"Socket is bound to an address & port number.\")\n",
    "        self.soc.listen(1)\n",
    "        self.connection, client_info = self.soc.accept()\n",
    "        # print(\"Running a Thread for the Connection with client\")\n",
    "        # print(self.port)\n",
    "        self.std=std\n",
    "        # self.lg=lg\n",
    "        # self.m=m\n",
    "        self.i=i\n",
    "        self.new_weights=[]\n",
    "    \n",
    "        \n",
    "\n",
    "    def run(self):\n",
    "       \n",
    "        \n",
    "\n",
    "        # This while loop allows the server to wait for the client to send data more than once within the same connection.\n",
    "       \n",
    "        received_data = self.recv()\n",
    "        self.reply(received_data)\n",
    "            \n",
    "\n",
    "            # print(received_data)\n",
    "            \n",
    "\n",
    "    def recv(self):\n",
    "        # print(\"nnnn\")\n",
    "        received_data = b\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                data = self.connection.recv(self.buffer_size)\n",
    "                received_data = data\n",
    "                \n",
    "                if len(received_data) > 0:\n",
    "                    # print('hnn')\n",
    "                    try:\n",
    "                        # Decoding the data (bytes).\n",
    "                        received_data = pickle.loads(received_data)\n",
    "                        # Returning the decoded data.\n",
    "                        return received_data\n",
    "\n",
    "                    except BaseException as e:\n",
    "                        print(\"Error Decoding the Client's Data:\")\n",
    "                        return\n",
    "\n",
    "\n",
    "            except BaseException as e:\n",
    "                print(\"Error Receiving Data from the Client: \")\n",
    "                return\n",
    "\n",
    "\n",
    "    def reply(self, received_data):\n",
    "        global keras_ga,data_inputs, data_outputs,globalmodel\n",
    "        if received_data is None:\n",
    "            print(\"nothong received from client\")\n",
    "        else:\n",
    "            score = globalmodel.evaluate(x_test, y_test, verbose=0)\n",
    "            if score[1] == 1.0:\n",
    "                print(\"model is updated correctly\")\n",
    "                self.soc.close()\n",
    "                return\n",
    "            else:\n",
    "                try:\n",
    "                    response = pickle.dumps(globalmodel)\n",
    "                    self.model_averaging(globalmodel, received_data)\n",
    "                except BaseException as e:\n",
    "                    print(\"Error Encoding the Message: {msg}.\\n\".format(msg=e))\n",
    "        score = globalmodel.evaluate(x_test, y_test, verbose=0)\n",
    "        # print('Test Score:', score[0])\n",
    "\n",
    "    \n",
    "\n",
    "    def model_averaging(self, model, received):\n",
    "        model_weights_vector = pygad.kerasga.model_weights_as_vector(model=model)\n",
    "        model_weights_matrix = pygad.kerasga.model_weights_as_matrix(model=model,\n",
    "                                                                     weights_vector=model_weights_vector)\n",
    "        best_model_weights_vector = pygad.kerasga.model_weights_as_vector(model=received)\n",
    "        best_model_weights_matrix = pygad.kerasga.model_weights_as_matrix(model=received,weights_vector=best_model_weights_vector)\n",
    "       \n",
    "        \n",
    "        new_weights = np.array(len(model_weights_matrix))\n",
    "        best=np.array(len(best_model_weights_matrix))\n",
    "        for i in range(0,len((model_weights_matrix))):\n",
    "            new_weights=np.append(new_weights,model_weights_matrix[i])\n",
    "        for i in range(0,len((best_model_weights_matrix))):\n",
    "            best=np.append(best,best_model_weights_matrix[i])\n",
    "        try:\n",
    "            new_wei = model_weights_matrix\n",
    "            for idx, arr in enumerate(new_wei):\n",
    "                new_wei[idx] = new_wei[idx] + best_model_weights_matrix[idx]\n",
    "                new_wei[idx] = new_wei[idx] / 2\n",
    "        except:\n",
    "            malicious.append(self.i)\n",
    "            self.soc.close()\n",
    "            lock = threading.Lock()\n",
    "            lock.acquire()\n",
    "        \n",
    "\n",
    "        W=np.array(len(new_wei))\n",
    "        for i in range(0,len((new_wei))):\n",
    "            W=np.append(W,new_wei[i])\n",
    "    \n",
    "        dist=np.linalg.norm(W-new_weights)\n",
    "        # print(\"distance:\" ,dist)\n",
    "        distance=str(dist)\n",
    "        with open(back_up, 'w') as w:\n",
    "            w.write(distance)\n",
    "  \n",
    "    def distancex(self):\n",
    "        # x=pickle.load(open(\"save.p\",\"rb\"))\n",
    "        if os.path.isfile(back_up):\n",
    "            with open(back_up, 'r') as r:\n",
    "                score = r.read()\n",
    "                return score\n",
    "    def full_aggregation(self,b):\n",
    "        if b:\n",
    "            try:\n",
    "                if os.path.isfile(models):\n",
    "                    with open(models, 'r') as r:\n",
    "                        \n",
    "                        new_weights = float([line.rstrip('\\n') for line in r])\n",
    "                \n",
    "                        globalmodel.set_weights(weights=new_weights)\n",
    "                        return True\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        \n",
    "port= 5680\n",
    "m=100\n",
    "lg=0\n",
    "std=[]\n",
    "listenThread = SocketThread(buffer_size=1024*1024*1024,\n",
    "                                port=5680,i=1)\n",
    "listenThread.start()\n",
    "d1=listenThread.distancex()\n",
    "d1=float(d1)\n",
    "listenThread2 = SocketThread(buffer_size=1024*1024*1024,\n",
    "                                port=5681,i=2)\n",
    "listenThread2.start()\n",
    "d2=listenThread2.distancex()\n",
    "d2=float(d2)\n",
    "listenThread3 = SocketThread(buffer_size=1024*1024*1024,\n",
    "                                port=5682,i=3)\n",
    "    # port+=1\n",
    "listenThread3.start()\n",
    "d3=listenThread3.distancex()\n",
    "d3=float(d3)\n",
    "\n",
    "listenThread4 = SocketThread(buffer_size=1024*1024*1024,\n",
    "                                port=5683,i=4)\n",
    "    # port+=1\n",
    "listenThread4.start()\n",
    "d4=listenThread4.distancex()\n",
    "d4=float(d4)\n",
    "listenThread5 = SocketThread(buffer_size=1024*1024*1024,\n",
    "                                port=5684,i=5)\n",
    "    # port+=1\n",
    "listenThread5.start()\n",
    "d5=listenThread5.distancex()\n",
    "d5=float(d5)\n",
    "listenThread6 = SocketThread(buffer_size=1024*1024*1024,\n",
    "                                port=5685,i=6)\n",
    "    # port+=1\n",
    "# listenThread6.start()\n",
    "# d6=listenThread6.distancex()\n",
    "# d6=float(d6)\n",
    "\n",
    "# listenThread7 = SocketThread(buffer_size=1024*1024*1024,\n",
    "#                                 port=5686,i=7)\n",
    "# listenThread7.start()\n",
    "# d7=listenThread7.distancex()\n",
    "# d7=float(d7)\n",
    "# listenThread8 = SocketThread(buffer_size=1024*1024*1024,\n",
    "#                                 port=5687,i=8)\n",
    "# listenThread8.start()\n",
    "# d8=listenThread8.distancex()\n",
    "# d8=float(d8)\n",
    "\n",
    "std=np.append(std,d1)\n",
    "std=np.append(std,d2)\n",
    "std=np.append(std,d3)\n",
    "std=np.append(std,d4)\n",
    "std=np.append(std,d5)\n",
    "# std=np.append(std,d6)\n",
    "# std=np.append(std,d7)\n",
    "# std=np.append(std,d8)\n",
    "print(std)\n",
    "mean=np.mean(std)\n",
    "print(mean)\n",
    "stdx=np.std(std,axis=0)\n",
    "print(\"std\",stdx)\n",
    "\n",
    "if d1 > mean+stdx or d1 < mean-stdx or d1==0:\n",
    "    malicious.append(1)\n",
    "    b=False\n",
    "\n",
    "else:\n",
    "    b=True\n",
    "    listenThread.full_aggregation(b)\n",
    "if d2 > mean+stdx or d2 < mean-stdx or d2==0:\n",
    "    malicious.append(2)\n",
    "    b=False\n",
    "\n",
    "else:\n",
    "    b=True\n",
    "    listenThread2.full_aggregation(b)\n",
    "if d3 > mean+stdx or d3 < mean-stdx or d3==0:\n",
    "    malicious.append(3)\n",
    "    b=False\n",
    "\n",
    "else:\n",
    "    b=True\n",
    "    listenThread3.full_aggregation(b)\n",
    "if d4 > mean+stdx or d4 < mean-stdx or d4==0:\n",
    "    malicious.append(4)\n",
    "    b=False\n",
    "\n",
    "else:\n",
    "    b=True\n",
    "    listenThread3.full_aggregation(b)\n",
    "\n",
    "if d5 > mean+stdx or d5 < mean-stdx or d5==0:\n",
    "    malicious.append(5)\n",
    "    b=False\n",
    "else:\n",
    "    b=True\n",
    "    listenThread3.full_aggregation(b)\n",
    "# if d6 > mean+stdx or d6 < mean-stdx or d6==0:\n",
    "#     malicious.append(6)\n",
    "#     b=False\n",
    "#     # print(\"client 6 is malicious outlying distance\")\n",
    "# else:\n",
    "#     b=True\n",
    "#     listenThread3.full_aggregation(b)\n",
    "# if d7 > mean+stdx or d7 < mean-stdx or d7==0:\n",
    "#     malicious.append(7)\n",
    "#     b=False\n",
    "#     print(\"client 7 is malicious outlying distance\")\n",
    "# else:\n",
    "#     b=True\n",
    "#     listenThread3.full_aggregation(b)\n",
    "# if d8 > mean+stdx or d8 < mean-stdx or d8==0:\n",
    "#     malicious.append(8)\n",
    "#     b=False\n",
    "#     # print(\"client 8 is malicious outlying distance\")\n",
    "# else:\n",
    "#     b=True\n",
    "#     listenThread3.full_aggregation(b)\n",
    "for v in malicious:\n",
    "    print(\"client\",v,\"is malicious\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ebaef70996a164ed53f0d2818090252f1afc348cdb48186a1059b38e106d308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
